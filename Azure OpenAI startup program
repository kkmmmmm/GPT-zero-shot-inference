#!/usr/bin/env python
# -*- coding: utf-8 -*-
r"""
run_prompts_via_proxy_no_verify_gpt5_mm_responses.py
ï¼ˆ/mnt/data/mrs3_prompts.csv å„ªå…ˆå–ã‚Šè¾¼ã¿ + ç”»åƒåŒæ¢±ãƒ»ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€å¯¾å¿œ + image_fileå„ªå…ˆ + XLSX/CSV ä¿å­˜
  + GPT-5 Responses API / reasoning å›ºå®š / verbosity=low / ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ 240s / HTTP2è‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰

- å…¥åŠ›å„ªå…ˆé †:
    1) /mnt/data/mrs3_prompts.csv      â† æ·»ä»˜CSVã‚’æœ€å„ªå…ˆ
    2) <Desktop>/mrs3_prompts.csv
    3) <Desktop>/ih_mortality_prompts.csv
    4) <Desktop>/prompts.xlsx / prompts.csv
  å¿…é ˆåˆ—: id, promptï¼ˆidã¯æ•°å­—ã‚’æŠ½å‡ºã—ã¦7æ¡åŒ–ï¼‰ï¼ä»»æ„: image_fileï¼ˆ; ã¾ãŸã¯ , åŒºåˆ‡ã‚Šã§è¤‡æ•°å¯ï¼‰
  â€» è¡¨å½¢å¼ã®æ‚£è€…ãƒ‡ãƒ¼ã‚¿ã¯ prompt å†…ã« Markdown ãƒ†ãƒ¼ãƒ–ãƒ«ç­‰ã§åŸ‹ã‚è¾¼ã‚“ã§OK

- ç”»åƒãƒ«ãƒ¼ãƒˆå€™è£œï¼ˆæœ€åˆã«è¦‹ã¤ã‹ã£ãŸã‚‚ã®ã‚’ä½¿ç”¨ï¼‰:
    <Desktop>/ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«, <Desktop>/ç”»åƒãƒ‡ãƒ¼ã‚¿, /mnt/data/ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«, /mnt/data/ç”»åƒãƒ‡ãƒ¼ã‚¿

- å‡ºåŠ›: <Desktop>/prompts_results.xlsx ã¨ <Desktop>/prompts_results.csv

- é€ä¿¡: Azure OpenAI (GPT-5, Responses API, api-version=preview) ã«
        input=[{"role":"user","content":[{"type":"input_text"}, {"type":"input_image"}, ...]}] ã§é€ä¿¡
  ãƒ»reasoning ã¯æŒ‡å®šå€¤ã‚’å³æ ¼ã«ä½¿ç”¨ï¼ˆè‡ªå‹•ãƒ€ã‚¦ãƒ³ã‚°ãƒ¬ãƒ¼ãƒ‰ç„¡ã—ï¼‰
  ãƒ»verbosity ã¯å¸¸ã« low
  ãƒ»HTTP ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã¯ 240sï¼ˆHTTP/2 ã¯ h2 ãŒå…¥ã£ã¦ã„ã‚‹å ´åˆã®ã¿ã€‚æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ™‚ã¯è‡ªå‹•ã§ HTTP/1.1ï¼‰
"""

import os
import sys
import time
import base64
import mimetypes
import csv
from pathlib import Path
from typing import List, Dict, Optional, Tuple

import pandas as pd
import httpx
from dotenv import load_dotenv
from openai import AzureOpenAI

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ãƒ¦ãƒ¼ã‚¶è¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
DESKTOP_DIR: Path        = Path(r"\\FRedirect\desktop$\mk07637")
DEFAULT_CSVS: List[str]  = ["mrs3_prompts.csv", "ih_mortality_prompts.csv", "prompts.xlsx", "prompts.csv"]
OUTPUT_FILE_NAME: str    = "prompts_results.xlsx"
OUTPUT_CSV_NAME: str     = "prompts_results.csv"
IMAGES_DIR_CANDIDATES    = ("ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«", "ç”»åƒãƒ‡ãƒ¼ã‚¿")
MAX_RETRIES: int         = 3
WAIT_SEC: int            = 2
FALLBACK_TEXT: str       = "I do not know"
REQUIRE_IMAGE: bool      = True   # ç”»åƒå¿…é ˆï¼ˆè¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã°é€ä¿¡ã‚¹ã‚­ãƒƒãƒ—ï¼‰

# reasoning ã‚’å›ºå®šï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ãªã„ï¼‰
STRICT_REASONING: bool   = True
REASONING_EFFORT: str    = "high"   # "minimal" / "low" / "medium" / "high"

# HTTP ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
HTTP_TIMEOUT_SEC: float  = 240.0
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #

# --- ãƒªãƒˆãƒ©ã‚¤å¯¾è±¡ä¾‹å¤–ï¼ˆSDKå·®åˆ†ã‚’å¸åï¼‰ ---
try:
    from openai import error as _openai_error  # v0ç³»
    RETRY_ERRORS = (_openai_error.Timeout, _openai_error.APIError, _openai_error.RateLimitError)
except Exception:
    try:
        from openai import APIError, RateLimitError, APITimeoutError  # v1ç³»
        RETRY_ERRORS = (APITimeoutError, APIError, RateLimitError)
    except Exception:
        RETRY_ERRORS = (Exception,)

# --- èªè¨¼ãƒ»ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ ---
# .env ã¯ã€ŒOPENAI_API_KEY / AZURE_OPENAI_ENDPOINT / OPENAI_DEPLOYMENT_NAMEï¼ˆgpt-5 ç­‰ï¼‰ã€ã®ã¿ã§OK
load_dotenv(override=True)
api_key     = os.getenv("OPENAI_API_KEY")
endpoint    = os.getenv("AZURE_OPENAI_ENDPOINT")  # ä¾‹: https://<resource>.cognitiveservices.azure.com
deployment  = os.getenv("OPENAI_DEPLOYMENT_NAME", "gpt-5")
if not api_key or not endpoint:
    raise RuntimeError("âŒ OPENAI_API_KEY / AZURE_OPENAI_ENDPOINT ãŒæœªè¨­å®šã§ã™ã€‚")

# ãƒ—ãƒ­ã‚­ã‚·ï¼ˆæœªè¨­å®šãªã‚‰ãƒ­ãƒ¼ã‚«ãƒ«æ—¢å®šï¼‰
os.environ.setdefault("HTTP_PROXY",  os.getenv("HTTP_PROXY",  "http://localhost:3128"))
os.environ.setdefault("HTTPS_PROXY", os.getenv("HTTPS_PROXY", "http://localhost:3128"))

# --- HTTP/2 è‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ ---
try:
    import h2  # noqa: F401
    _http2 = True
except Exception:
    _http2 = False
    print("â„¹ï¸ h2 æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã®ãŸã‚ HTTP/1.1 ã§æ¥ç¶šã—ã¾ã™ï¼ˆhttp2=Falseï¼‰", file=sys.stderr)

# httpx ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆSSLæ¤œè¨¼ã‚ªãƒ•ãƒ»æ¥ç¶šãƒ—ãƒ¼ãƒ«ãƒ»HTTP/2ã¯å¯èƒ½æ™‚ã®ã¿ï¼‰
http_client = httpx.Client(
    verify=False,             # â† é–‹ç™ºç”¨é€”ã®ã¿ï¼ˆæœ¬ç•ªã¯ç¤¾å†…CAè¨¼æ˜æ›¸ã‚’æŒ‡å®šï¼‰
    timeout=HTTP_TIMEOUT_SEC,
    trust_env=True,
    http2=_http2,
    limits=httpx.Limits(max_connections=20, max_keepalive_connections=20),
)

# Azure OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆResponses API ã¯ /openai/v1/ & api-version=previewï¼‰
client = AzureOpenAI(
    api_key=api_key,
    base_url=f"{endpoint}/openai/v1/",
    api_version="preview",
    http_client=http_client,
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å…¥åŠ›ãƒ»ç”»åƒæ¢ç´¢ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #

def resolve_input_path(desk: Path) -> Path:
    """å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¢ç´¢ã€‚/mnt/data/mrs3_prompts.csv ã‚’æœ€å„ªå…ˆã€‚"""
    mnt = Path("/mnt/data")
    first = mnt / "mrs3_prompts.csv"
    if first.exists():
        return first
    desktop_candidates = [desk / name for name in DEFAULT_CSVS]
    mnt_candidates = [mnt / name for name in DEFAULT_CSVS if name != "mrs3_prompts.csv"]
    for p in [*desktop_candidates, *mnt_candidates]:
        if p.exists():
            return p
    raise FileNotFoundError("Prompt file not found in expected locations.")

def resolve_images_dir(desk: Path) -> Path:
    """ç”»åƒãƒ«ãƒ¼ãƒˆå€™è£œã‚’ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—å„ªå…ˆã§æ¢ç´¢ã€‚ç„¡ã‘ã‚Œã° /mnt/data å´ã‚‚ç¢ºèªã€‚"""
    mnt = Path("/mnt/data")
    for base in (desk, mnt):
        for name in IMAGES_DIR_CANDIDATES:
            p = base / name
            if p.exists():
                return p
    raise FileNotFoundError("ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ï¼ˆç”»åƒãƒ•ã‚¡ã‚¤ãƒ«/ç”»åƒãƒ‡ãƒ¼ã‚¿ï¼‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

def load_rows(path: Path) -> pd.DataFrame:
    """id, prompt, (ä»»æ„)image_file ã‚’èª­ã‚€ã€‚A=ID, B=JPN ãªã©ã«ã‚‚å¯¾å¿œã€‚"""
    df = pd.read_csv(path) if path.suffix.lower() == ".csv" else pd.read_excel(path)
    cmap = {c.lower(): c for c in df.columns}

    id_col = (cmap.get("id") or cmap.get("image_id") or cmap.get("id7")
              or cmap.get("ç”»åƒid") or cmap.get("æ‚£è€…id") or df.columns[0])
    prompt_col = (cmap.get("prompt") or cmap.get("jpn") or cmap.get("æ—¥æœ¬èª")
                  or cmap.get("text") or (df.columns[1] if len(df.columns) > 1 else df.columns[0]))
    img_col = cmap.get("image_file")  # ä»»æ„

    use_cols = [id_col, prompt_col] + ([img_col] if img_col else [])
    out = df[use_cols].copy()
    out.columns = ["id", "prompt"] + (["image_file"] if img_col else [])

    def to_id7(x):
        digits = "".join(ch for ch in str(x).strip() if ch.isdigit())
        return f"{int(digits):07d}"
    out["id"] = out["id"].apply(to_id7)
    return out

def find_images_for_id(images_root: Path, id7: str) -> List[Path]:
    """<root>/<id>/ï¼ˆå„ªå…ˆï¼‰ã€ç„¡ã‘ã‚Œã° <root>/ ç›´ä¸‹ã‹ã‚‰ <id>*.png|.jpg|.jpeg ã‚’å–å¾—"""
    patterns = (f"{id7}*.png", f"{id7}*.jpg", f"{id7}*.jpeg")
    files: List[Path] = []
    subdir = images_root / id7
    if subdir.exists():
        for pat in patterns:
            files.extend(sorted(subdir.glob(pat)))
    else:
        for pat in patterns:
            files.extend(sorted(images_root.glob(pat)))
    return files

def resolve_image_list(images_root: Path, id7: str, image_file_val: Optional[str]) -> List[Path]:
    """image_file æŒ‡å®šãŒã‚ã‚Œã°å„ªå…ˆã€‚è¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã° <id>* æ¢ç´¢ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€‚"""
    if image_file_val and str(image_file_val).strip():
        names = [t.strip() for t in str(image_file_val).replace(";", ",").split(",") if t.strip()]
        files: List[Path] = []
        for name in names:
            p = Path(name)
            candidates = [p] if p.is_absolute() else [images_root / id7 / name, images_root / name]
            for c in candidates:
                if c.exists():
                    files.append(c); break
        if files:
            return files
    return find_images_for_id(images_root, id7)

def to_data_url(p: Path) -> str:
    mime, _ = mimetypes.guess_type(p.name)
    if not mime:
        mime = "image/jpeg"
    b64 = base64.b64encode(p.read_bytes()).decode("ascii")
    return f"data:{mime};base64,{b64}"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Responses API å‘¼ã³å‡ºã— â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #

def build_user_content(prompt_text: str, image_paths: List[Path]) -> List[Dict]:
    """
    Responses API ã® input ç”¨ content ã‚’æ§‹ç¯‰ï¼ˆãƒ†ã‚­ã‚¹ãƒˆ + è¤‡æ•°ç”»åƒï¼‰ã€‚
    - ãƒ†ã‚­ã‚¹ãƒˆéƒ¨ã¯ clinical/CT ä½µç”¨ã®æ˜ç¤ºæŒ‡ç¤ºã‚’å«ã‚ã‚‹
    - ç”»åƒã¯ Data URL æ–‡å­—åˆ—ã§æ·»ä»˜ï¼ˆâ€» image_url ã¯ dict ã§ã¯ãªã strï¼‰
    """
    preface = (
        "You must analyze the attached non-contrast head CT image(s) and explicitly state the image findings "
        "(e.g., hemorrhage location, intraventricular extension, mass effect/midline shift, and approximate hematoma volume via ABC/2 when feasible). "
        "In your reasoning and final answer, interleave findings from the CT image(s) with the Patient Data provided in the text, "
        "clearly labeling which evidence comes from imaging vs. patient data."
    )
    content: List[Dict] = [
        {"type": "input_text", "text": f"{preface}\n\n{prompt_text}"},
    ]
    for p in image_paths:
        # â˜… ä¿®æ­£ç‚¹ï¼šimage_url ã‚’ {"url": ...} ã§ã¯ãªãã€Data URL ã®ã€Œæ–‡å­—åˆ—ã€ã§æ¸¡ã™
        content.append({"type": "input_image", "image_url": to_data_url(p)})
    return content

def _extract_text_from_response(resp) -> str:
    """Responses API ã®å‡ºåŠ›ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã€‚output_text ã‚’å„ªå…ˆã€ç„¡ã‘ã‚Œã° content é…åˆ—ã‚’èµ°æŸ»ã€‚"""
    text = getattr(resp, "output_text", None)
    if text:
        return text.strip()
    try:
        parts = []
        for item in getattr(resp, "output", []) or []:
            for c in getattr(item, "content", []) or []:
                if getattr(c, "type", "") in ("output_text", "text"):
                    t = getattr(c, "text", "")
                    if t:
                        parts.append(t)
        text = "".join(parts).strip()
        if text:
            return text
    except Exception:
        pass
    return ""

def responses_once(user_content: List[Dict]) -> Tuple[str, Optional[str]]:
    """
    Responses API ã« 1 å›å•ã„åˆã‚ã›ã¦ (å¿œç­”æ–‡å­—åˆ—, ã‚¨ãƒ©ãƒ¼æ–‡å­—åˆ—) ã‚’è¿”ã™ã€‚
    - reasoning ã¯ STRICT ã«å›ºå®šï¼ˆéå¯¾å¿œã§ã‚‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ãªã„ï¼‰
    - verbosity ã¯å¸¸ã« low
    """
    system_instructions = (
        "You are a stroke specialist. Always use both the Patient Data and any attached non-contrast head CT image(s). "
        "Provide a concise, clinically useful final answer. Do NOT include chain-of-thought."
    )

    for attempt in range(1, MAX_RETRIES + 1):
        try:
            kwargs = dict(
                model=deployment,
                instructions=system_instructions,
                input=[{"role": "user", "content": user_content}],
                text={"verbosity": "low"},  # å‡ºåŠ›é‡ã‚’æŠ‘åˆ¶
            )
            if STRICT_REASONING:
                kwargs["reasoning"] = {"effort": REASONING_EFFORT}

            resp = client.responses.create(**kwargs)
            text = _extract_text_from_response(resp)
            return (text if text else FALLBACK_TEXT, None)

        except RETRY_ERRORS as exc:
            msg = str(exc)
            if "not supported" in msg.lower() or "unknown parameter" in msg.lower():
                return (FALLBACK_TEXT, f"request failed (reasoning='{REASONING_EFFORT}', verbosity='low'): {msg}")
            if attempt == MAX_RETRIES:
                return (FALLBACK_TEXT, f"request failed after retries (reasoning='{REASONING_EFFORT}', verbosity='low'): {msg}")
            backoff = WAIT_SEC * attempt
            print(f"[Retry {attempt}/{MAX_RETRIES}] {exc} â†’ wait {backoff}s", file=sys.stderr)
            time.sleep(backoff)

        except Exception as exc:
            return (FALLBACK_TEXT, f"unexpected error (reasoning='{REASONING_EFFORT}', verbosity='low'): {exc}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ä¿å­˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #

def save_results(results: List[Dict[str, str]], xlsx_path: Path, csv_path: Path) -> None:
    if not results:
        print("âš ï¸  ä¿å­˜å¯¾è±¡ãŒç©ºã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—", file=sys.stderr); return
    df = pd.DataFrame(results)
    with pd.ExcelWriter(xlsx_path, engine="xlsxwriter") as w:
        df.to_excel(w, index=False, sheet_name="results")
    print(f"âœ… Results saved (xlsx): {xlsx_path}")
    df.to_csv(csv_path, index=False, encoding="utf-8-sig", quoting=csv.QUOTE_ALL)
    print(f"âœ… Results saved (csv):  {csv_path}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ãƒ¡ã‚¤ãƒ³ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #

def main() -> None:
    input_path  = resolve_input_path(DESKTOP_DIR)
    output_xlsx = DESKTOP_DIR / OUTPUT_FILE_NAME
    output_csv  = DESKTOP_DIR / OUTPUT_CSV_NAME
    images_dir  = resolve_images_dir(DESKTOP_DIR)

    print(f"ğŸ“¥ Loading prompts from: {input_path}")
    df = load_rows(input_path)
    print(f"âœ… {len(df)} rows loaded")
    print(f"ğŸ–¼  Using images root: {images_dir}")

    results: List[Dict[str, str]] = []
    try:
        for i, r in enumerate(df.itertuples(index=False), 1):
            id7: str = r.id
            prompt_text: str = r.prompt
            image_file_val: Optional[str] = getattr(r, "image_file", None) if hasattr(r, "image_file") else None

            img_paths = resolve_image_list(images_dir, id7, image_file_val)

            if not img_paths:
                msg = f"âš ï¸  {id7}: ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚REQUIRE_IMAGE=True ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚"
                print(msg, file=sys.stderr)
                results.append({
                    "id": id7,
                    "n_images": 0,
                    "images": "",
                    "prompt": prompt_text,
                    "response": "SKIPPED (no images found)",
                    "reasoning_effort": REASONING_EFFORT if STRICT_REASONING else "",
                    "error": ""
                })
                if REQUIRE_IMAGE:
                    continue  # é€ä¿¡ã—ãªã„

            user_content = build_user_content(prompt_text, img_paths)
            print(f"[{i}/{len(df)}] queryingâ€¦ id={id7} images={len(img_paths)}")

            ans, err = responses_once(user_content)

            results.append({
                "id": id7,
                "n_images": len(img_paths),
                "images": ";".join(p.name for p in img_paths),
                "prompt": prompt_text,
                "response": ans,
                "reasoning_effort": REASONING_EFFORT if STRICT_REASONING else "",
                "error": err or ""
            })
    finally:
        print(f"ğŸ’¾ Saving â†’ {output_xlsx}, {output_csv}")
        save_results(results, output_xlsx, output_csv)

    print("ğŸ‰ All done!")

if __name__ == "__main__":
    main()
